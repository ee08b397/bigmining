package edu.fiu.cs.bigmining.generator.vector;

import org.apache.commons.cli2.CommandLine;
import org.apache.commons.cli2.Group;
import org.apache.commons.cli2.Option;
import org.apache.commons.cli2.builder.ArgumentBuilder;
import org.apache.commons.cli2.builder.DefaultOptionBuilder;
import org.apache.commons.cli2.builder.GroupBuilder;
import org.apache.commons.cli2.commandline.Parser;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;
import org.apache.mahout.math.VectorWritable;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import edu.fiu.cs.bigmining.generator.DummyInputFormat;
import edu.fiu.cs.bigmining.util.ParserUtil;

/**
 * Randomly generate a set of double vectors.
 * 
 */
public class RandomVectorGenerator extends Configured implements Tool {
  
  private static final Logger log = LoggerFactory.getLogger(RandomVectorGenerator.class);
  
  /* The directory path of the output */
  private String outputPathStr;

  /* Whether to overwrite the existing directory */
  private boolean isOverwrite;
  
  /* The host of the file system        */
  private String host;
  
  /* The port of the file system        */
  private String fsPort;
  
  /* The port of the job tracker        */
  private String jobTrackerPort;

  /* The number of vectors to generate */
  private long numVectorsPerMapper;

  /* The size of dimension of the features */
  private int featureDimension;

  /* Whether the label for regression or for classification */
  private boolean isRegression;

  /* The size of dimension of the labels */
  private int labelDimension;

  /**
   * Parse the arguments.
   * 
   * @param args
   * @return
   */
  private boolean parseArgs(String[] args) {
    log.info("Validating the arguments...");
    DefaultOptionBuilder optionBuilder = new DefaultOptionBuilder();
    GroupBuilder groupBuilder = new GroupBuilder();
    ArgumentBuilder argumentBuilder = new ArgumentBuilder();
    
    Option overwriteOption = optionBuilder.withLongName("overwrite")
        .withShortName("ow")
        .withDescription("Whether overwrites the existing files.")
        .withRequired(false).create();
    
    Option hostOption = optionBuilder
        .withLongName("host")
        .withShortName("h")
        .withDescription("The host of the file system.")
        .withRequired(true)
        .withArgument(
            argumentBuilder.withDefault("localhost").withMinimum(1).withMaximum(1).create()).create();
    
    Option fsPortOption = optionBuilder
        .withLongName("file-system-port")
        .withShortName("fp")
        .withDescription("The port of the file system.")
        .withRequired(false)
        .withArgument(
            argumentBuilder.withDefault(30002).withMinimum(1).withMaximum(1).create()).create();
    
    Option mapredPortOption = optionBuilder
        .withLongName("job-tracker-port")
        .withShortName("jtp")
        .withDescription("The job tracker port of the cluster.")
        .withRequired(false)
        .withArgument(
            argumentBuilder.withDefault(30001).withMinimum(1).withMaximum(1).create()).create();

    Group outputParameterGroup = groupBuilder.withOption(overwriteOption)
        .withOption(hostOption).withOption(fsPortOption).withOption(mapredPortOption).create();

    Option outputPathOption = optionBuilder
        .withLongName("output")
        .withShortName("o")
        .withDescription("The directory path of output files.")
        .withArgument(
            argumentBuilder.withName("path").withMinimum(1).withMaximum(1)
                .create()).withRequired(true).withChildren(outputParameterGroup)
        .create();
    
    Option numVectorsPerMapperOption = optionBuilder
        .withLongName("number-vectors-per-mapper")
        .withShortName("size")
        .withDescription("Number of vectors generated by each mapper.").withRequired(true)
        .withArgument(
            argumentBuilder.withDefault(100).withMinimum(1).withMaximum(1).create()).create();
    
    Option featureDimensionOption = optionBuilder
        .withLongName("featureDimension").withShortName("fd")
        .withDescription("The number of dimensions for the features.")
        .withRequired(true)
        .withArgument(argumentBuilder.withMinimum(1).withMaximum(1).create())
        .create();
    
    Option labelsDimensionOption = optionBuilder
        .withLongName("featureDimension").withShortName("ld")
        .withDescription("The number of dimensions for the labels.")
        .withRequired(true)
        .withArgument(argumentBuilder.withMinimum(1).withMaximum(1).create())
        .create();
    
    Option vectorTypeOption = optionBuilder
        .withLongName("type")
        .withShortName("t")
        .withDescription("The task type the generated data used for.")
        .withArgument(
            argumentBuilder.withDefault("regression").withMinimum(1)
                .withMaximum(1).create()).create();

    Parser parser = new Parser();
    Group normalGroup = groupBuilder.withOption(outputPathOption)
        .withOption(overwriteOption).withOption(hostOption)
        .withOption(fsPortOption).withOption(featureDimensionOption)
        .withOption(mapredPortOption).withOption(numVectorsPerMapperOption)
        .withOption(labelsDimensionOption).withOption(vectorTypeOption).create();
    
    parser.setGroup(normalGroup);
    
    CommandLine cli = parser.parseAndHelp(args);
    if (cli == null) {
      return false;
    }
    
    this.outputPathStr = ParserUtil.getString(cli, outputPathOption);
    this.isOverwrite = ParserUtil.getBoolean(cli, overwriteOption);
    this.host = ParserUtil.getString(cli, hostOption);
    this.fsPort = ParserUtil.getString(cli, fsPortOption);
    this.jobTrackerPort = ParserUtil.getString(cli, mapredPortOption);
    
    this.numVectorsPerMapper = ParserUtil.getLong(cli, numVectorsPerMapperOption);
    this.featureDimension = ParserUtil.getInteger(cli, featureDimensionOption);
    this.labelDimension = ParserUtil.getInteger(cli, labelsDimensionOption);
    this.isRegression = ParserUtil.getString(cli, vectorTypeOption).equalsIgnoreCase("regression")? true : false;
    
    log.info(String.format("Output directory: %s", outputPathStr));
    log.info(String.format("Overwrite: %s", isOverwrite));
    log.info(String.format("Host: %s", host));
    log.info(String.format("File system port: %s", fsPort));
    log.info(String.format("Job tracker port: %s", jobTrackerPort));
    log.info(String.format("Number of vectors per mapper: %s", numVectorsPerMapper));
    log.info(String.format("Feature dimension: %d", featureDimension));
    log.info(String.format("Label dimension: %d", labelDimension));
    
    return true;
  }
  
  public int run(String[] args) throws Exception {

    if (!parseArgs(args)) {
      return -1;
    }

    log.info("Initializing job...");
    Configuration conf = new Configuration(getConf());
    
    conf.set("fs.defaultFS", String.format("hdfs://%s:%s", host, fsPort));
    conf.set("mapred.job.tracker", String.format("%s:%s", host, jobTrackerPort));
    
    conf.setInt("feature.dimension", this.featureDimension);
    conf.setInt("label.dimension", this.labelDimension);
    conf.setBoolean("regression", this.isRegression);
    conf.setLong("number.vectors.per.mapper", this.numVectorsPerMapper);

    Job job = new Job(conf);
    job.setJarByClass(RandomVectorGenerator.class);
    job.setJobName("Random Vector Generator");

    // validate the output path
    Path outputPath = new Path(this.outputPathStr);
    FileSystem fs = outputPath.getFileSystem(conf);
    log.info(String.format("File system: %s", fs.getUri()));
    if (fs.exists(outputPath)) {
      if (!this.isOverwrite) {
        log.info(String.format("Directory %s already exists.", this.outputPathStr));
        return -1;
      } else {
        fs.delete(outputPath, true);
      }
    }

    job.setInputFormatClass(DummyInputFormat.class);
    job.setOutputFormatClass(SequenceFileOutputFormat.class);
    job.setOutputKeyClass(NullWritable.class);
    job.setOutputValueClass(VectorWritable.class);

    job.setMapperClass(RandomVectorGeneratorMapper.class);
    job.setReducerClass(DummyReducer.class);
    job.setNumReduceTasks(0);

    FileOutputFormat.setOutputPath(job, outputPath);

    job.waitForCompletion(true);
    
    log.info("Job finished.");

    return 0;
  }
  
  public static void main(String[] args) throws Exception {
    
    int exitCode = ToolRunner.run(new RandomVectorGenerator(), args);
    System.exit(exitCode);
    
  }

}
